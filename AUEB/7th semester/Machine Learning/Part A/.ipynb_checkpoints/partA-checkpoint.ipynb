{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9aa23d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13/12/2016</td>\n",
       "      <td>780.646973</td>\n",
       "      <td>788.460022</td>\n",
       "      <td>777.961975</td>\n",
       "      <td>780.556030</td>\n",
       "      <td>780.556030</td>\n",
       "      <td>81645600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>780.005005</td>\n",
       "      <td>782.033997</td>\n",
       "      <td>776.838989</td>\n",
       "      <td>781.481018</td>\n",
       "      <td>781.481018</td>\n",
       "      <td>75979000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>780.070007</td>\n",
       "      <td>781.434998</td>\n",
       "      <td>777.802002</td>\n",
       "      <td>778.088013</td>\n",
       "      <td>778.088013</td>\n",
       "      <td>81580096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>778.963013</td>\n",
       "      <td>785.031982</td>\n",
       "      <td>778.963013</td>\n",
       "      <td>784.906982</td>\n",
       "      <td>784.906982</td>\n",
       "      <td>83608200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17/12/2016</td>\n",
       "      <td>785.166016</td>\n",
       "      <td>792.508972</td>\n",
       "      <td>784.864014</td>\n",
       "      <td>790.828979</td>\n",
       "      <td>790.828979</td>\n",
       "      <td>78989800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  13/12/2016  780.646973  788.460022  777.961975  780.556030  780.556030   \n",
       "1  14/12/2016  780.005005  782.033997  776.838989  781.481018  781.481018   \n",
       "2  15/12/2016  780.070007  781.434998  777.802002  778.088013  778.088013   \n",
       "3  16/12/2016  778.963013  785.031982  778.963013  784.906982  784.906982   \n",
       "4  17/12/2016  785.166016  792.508972  784.864014  790.828979  790.828979   \n",
       "\n",
       "       Volume  \n",
       "0  81645600.0  \n",
       "1  75979000.0  \n",
       "2  81580096.0  \n",
       "3  83608200.0  \n",
       "4  78989800.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize']=20,10\n",
    "\n",
    "dataset = pd.read_csv('BTC-USD.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39fbc9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 679us/step - loss: 0.1162\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 643us/step - loss: 0.0246\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 643us/step - loss: 0.0155\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 643us/step - loss: 0.0136\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 607us/step - loss: 0.0111\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 643us/step - loss: 0.0053\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 607us/step - loss: 0.0011\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 572us/step - loss: 4.5840e-04\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 607us/step - loss: 3.4620e-04\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 607us/step - loss: 2.7912e-04\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Predictions'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23684/615976410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1461\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1461\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;31m# remove NaN values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Predictions'"
     ]
    }
   ],
   "source": [
    "dataset[\"Date\"]=pd.to_datetime(dataset.Date,format = \"%d/%m/%Y\")\n",
    "dataset.index = dataset['Date']\n",
    "    \n",
    "new_dataset = pd.DataFrame(index=range(0,len(dataset)),columns=['Date','Close'])\n",
    "\n",
    "for i in range(0,len(dataset)):\n",
    "    new_dataset[\"Date\"][i] = dataset['Date'][i]\n",
    "    new_dataset[\"Close\"][i] = dataset[\"Close\"][i]    \n",
    "   \n",
    "# data normalization\n",
    "scaler = sk.preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "new_dataset.index=new_dataset.Date\n",
    "new_dataset.drop(\"Date\",axis=1,inplace=True)\n",
    "final_dataset = new_dataset.values\n",
    "\n",
    "\n",
    "train_data = final_dataset[0:1461,:] # 80% training data\n",
    "valid_data = final_dataset[1461:,:]   # 20% testing data \n",
    "\n",
    "\n",
    "\n",
    "scaler=sk.preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data=scaler.fit_transform(final_dataset)\n",
    "\n",
    "\n",
    "\n",
    "# remove NaN values\n",
    "scaled_data = scaled_data[~np.isnan(scaled_data)]\n",
    "scaled_data = scaled_data.reshape(-1,1)\n",
    "\n",
    "# pairnoume ta training data, 60 timesteps\n",
    "x_train_data,y_train_data=[],[]\n",
    "for i in range(60,len(train_data)):\n",
    "    x_train_data.append(scaled_data[i-60:i,0])\n",
    "    y_train_data.append(scaled_data[i,0])\n",
    "    \n",
    "\n",
    "    \n",
    "x_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data)\n",
    "x_train_data=np.reshape(x_train_data,(x_train_data.shape[0],x_train_data.shape[1],1))\n",
    "    \n",
    "# RNN implementation\n",
    "\"\"\"\n",
    "lstm_model=tf.keras.Sequential()\n",
    "lstm_model.add(LSTM(units = 50,return_sequences = True,input_shape=(x_train_data.shape[1],1)))\n",
    "lstm_model.add(LSTM(units = 50,return_sequences = True))\n",
    "lstm_model.add(LSTM(units = 50))\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "lstm_model.fit(x_train_data,y_train_data,epochs=10,batch_size=50) # mini batch size 50.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Dense NN implementation\n",
    "model = tf.keras.Sequential() # aplo NN implementation\n",
    "#model.add(Conv1D(filters = 50 , kernel_size = 10 , activation = 'relu', input_shape = (None,6)))\n",
    "model.add(Dense(50,input_dim = 60,activation = 'relu')) # input layer\n",
    "model.add(Dense(50,activation = 'relu')) # 1o hidden layer\n",
    "model.add(Dense(50,activation = 'relu')) # 2o hidden layer\n",
    "model.add(Dense(1,activation = 'sigmoid')) # output layer (xrhsimopoioume sigmoid gia to epithymito apotelesma)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_log = model.fit(x_train_data, y_train_data, epochs = 10, batch_size = 50) # mini batch me 50 ypodeigmata\n",
    "\n",
    "# etoimasia twn testing data.\n",
    "\n",
    "test_data = new_dataset[len(new_dataset)-len(valid_data)-60:].values\n",
    "test_data = test_data.reshape(-1,1)\n",
    "test_data = scaler.transform(test_data)\n",
    "print(type(test_data))\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,test_data.shape[0]):\n",
    "    X_test.append(test_data[i-60:i,0])\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "#model.fit(X_train, y_train)\n",
    "ypred = model.predict(X_test)\n",
    "ypred = scaler.inverse_transform(ypred)\n",
    "\n",
    "# provlepsh timhs bitcoin vasismenh stis times kleisimatos twn teleytaiwn 50 hmerwn\n",
    "train_data = new_dataset[:1461]\n",
    "test_data = new_dataset[1461:]\n",
    "test_data.loc[test_data['Predictions']] = ypred\n",
    "\n",
    "# remove NaN values\n",
    "print(type(train_data))\n",
    "#train_data = train_data[~np.isnan(train_data)]\n",
    "#test_data = test_data[~np.isnan(test_data)]\n",
    "plt.plot(train_data['Close'])\n",
    "plt.plot(test_data['Close',\"Predictions\"])\n",
    "\n",
    "\n",
    "#y_test.argmax(axis=-1) == ypred.argmax(axis=-1)\n",
    "#np.mean(y_test.argmax(axis=-1) == ypred.argmax(axis=-1))\n",
    "print(model.summary())\n",
    "\n",
    "#model_log = model.fit(X_train, y_train, epochs=10, batch_size=50) # mini batch me 50 ypodeigmata\n",
    "\n",
    "# sklearn.metrics.mean_squared_error(y_test,y_pred) # calculation of MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80ff7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1ee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
